{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b4ac338",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:42:35.812206Z",
     "iopub.status.busy": "2021-12-09T16:42:35.809953Z",
     "iopub.status.idle": "2021-12-09T16:42:37.290295Z",
     "shell.execute_reply": "2021-12-09T16:42:37.289613Z",
     "shell.execute_reply.started": "2021-12-09T16:06:56.109108Z"
    },
    "papermill": {
     "duration": 1.523733,
     "end_time": "2021-12-09T16:42:37.290465",
     "exception": false,
     "start_time": "2021-12-09T16:42:35.766732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "# import torchtext\n",
    "# from torchtext.data.utils import get_tokenizer\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4da3c56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:42:37.353137Z",
     "iopub.status.busy": "2021-12-09T16:42:37.352495Z",
     "iopub.status.idle": "2021-12-09T16:42:37.355725Z",
     "shell.execute_reply": "2021-12-09T16:42:37.356181Z",
     "shell.execute_reply.started": "2021-12-09T16:06:56.117174Z"
    },
    "papermill": {
     "duration": 0.03756,
     "end_time": "2021-12-09T16:42:37.356323",
     "exception": false,
     "start_time": "2021-12-09T16:42:37.318763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "754298a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:42:37.416385Z",
     "iopub.status.busy": "2021-12-09T16:42:37.415586Z",
     "iopub.status.idle": "2021-12-09T16:42:37.418513Z",
     "shell.execute_reply": "2021-12-09T16:42:37.418953Z",
     "shell.execute_reply.started": "2021-12-09T16:06:56.132662Z"
    },
    "papermill": {
     "duration": 0.035188,
     "end_time": "2021-12-09T16:42:37.419221",
     "exception": false,
     "start_time": "2021-12-09T16:42:37.384033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torchtext' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtorchtext\u001b[49m\u001b[38;5;241m.\u001b[39m__version__\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torchtext' is not defined"
     ]
    }
   ],
   "source": [
    "torchtext.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69d9dd7",
   "metadata": {
    "papermill": {
     "duration": 0.027331,
     "end_time": "2021-12-09T16:42:37.474666",
     "exception": false,
     "start_time": "2021-12-09T16:42:37.447335",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TorchText文本分类数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a209db18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:42:37.534610Z",
     "iopub.status.busy": "2021-12-09T16:42:37.533799Z",
     "iopub.status.idle": "2021-12-09T16:43:22.580554Z",
     "shell.execute_reply": "2021-12-09T16:43:22.579987Z",
     "shell.execute_reply.started": "2021-12-09T16:06:56.141621Z"
    },
    "papermill": {
     "duration": 45.078337,
     "end_time": "2021-12-09T16:43:22.580709",
     "exception": false,
     "start_time": "2021-12-09T16:42:37.502372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_iter, test_iter = torchtext.datasets.IMDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd58c99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:43:22.663316Z",
     "iopub.status.busy": "2021-12-09T16:43:22.662641Z",
     "iopub.status.idle": "2021-12-09T16:43:22.665372Z",
     "shell.execute_reply": "2021-12-09T16:43:22.665796Z",
     "shell.execute_reply.started": "2021-12-09T16:07:22.836195Z"
    },
    "papermill": {
     "duration": 0.04762,
     "end_time": "2021-12-09T16:43:22.665925",
     "exception": false,
     "start_time": "2021-12-09T16:43:22.618305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('neg', 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.')\n"
     ]
    }
   ],
   "source": [
    "print(next(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8731cef0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:43:22.746032Z",
     "iopub.status.busy": "2021-12-09T16:43:22.745419Z",
     "iopub.status.idle": "2021-12-09T16:43:22.749729Z",
     "shell.execute_reply": "2021-12-09T16:43:22.750106Z",
     "shell.execute_reply.started": "2021-12-09T16:07:22.849118Z"
    },
    "papermill": {
     "duration": 0.046558,
     "end_time": "2021-12-09T16:43:22.750270",
     "exception": false,
     "start_time": "2021-12-09T16:43:22.703712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'a', 'book', 'about', 'pytorch', '.']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer('basic_english')             # 初始化分词工具\n",
    "print(tokenizer('This is a book about PyTorch.'))      # 在英文语句上调用并打印分词结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a52b3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:43:22.829489Z",
     "iopub.status.busy": "2021-12-09T16:43:22.828729Z",
     "iopub.status.idle": "2021-12-09T16:43:51.160506Z",
     "shell.execute_reply": "2021-12-09T16:43:51.159308Z",
     "shell.execute_reply.started": "2021-12-09T16:07:22.858486Z"
    },
    "papermill": {
     "duration": 28.373402,
     "end_time": "2021-12-09T16:43:51.160672",
     "exception": false,
     "start_time": "2021-12-09T16:43:22.787270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_iter, test_iter = torchtext.datasets.IMDB()\n",
    "train_data, test_data = list(train_iter), list(test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90145a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:43:51.241158Z",
     "iopub.status.busy": "2021-12-09T16:43:51.240457Z",
     "iopub.status.idle": "2021-12-09T16:43:51.243375Z",
     "shell.execute_reply": "2021-12-09T16:43:51.243787Z",
     "shell.execute_reply.started": "2021-12-09T16:07:50.379973Z"
    },
    "papermill": {
     "duration": 0.044964,
     "end_time": "2021-12-09T16:43:51.243911",
     "exception": false,
     "start_time": "2021-12-09T16:43:51.198947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('neg',\n",
       " '\"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn\\'t matter what one\\'s political views are because this film can hardly be taken seriously on any level. As for the claim that frontal male nudity is an automatic NC-17, that isn\\'t true. I\\'ve seen R-rated films with male nudity. Granted, they only offer some fleeting views, but where are the R-rated films with gaping vulvas and flapping labia? Nowhere, because they don\\'t exist. The same goes for those crappy cable shows: schlongs swinging in the breeze but not a clitoris in sight. And those pretentious indie movies like The Brown Bunny, in which we\\'re treated to the site of Vincent Gallo\\'s throbbing johnson, but not a trace of pink visible on Chloe Sevigny. Before crying (or implying) \"double-standard\" in matters of nudity, the mentally obtuse should take into account one unavoidably obvious anatomical difference between men and women: there are no genitals on display when actresses appears nude, and the same cannot be said for a man. In fact, you generally won\\'t see female genitals in an American film in anything short of porn or explicit erotica. This alleged double-standard is less a double standard than an admittedly depressing ability to come to terms culturally with the insides of women\\'s bodies.')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c334b1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:43:51.327379Z",
     "iopub.status.busy": "2021-12-09T16:43:51.325530Z",
     "iopub.status.idle": "2021-12-09T16:43:51.328090Z",
     "shell.execute_reply": "2021-12-09T16:43:51.328550Z",
     "shell.execute_reply.started": "2021-12-09T16:07:50.387053Z"
    },
    "papermill": {
     "duration": 0.047631,
     "end_time": "2021-12-09T16:43:51.328673",
     "exception": false,
     "start_time": "2021-12-09T16:43:51.281042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_classes = set([label for (label, text) in train_data])\n",
    "num_class = len(all_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d951f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:43:51.409293Z",
     "iopub.status.busy": "2021-12-09T16:43:51.408656Z",
     "iopub.status.idle": "2021-12-09T16:43:51.411253Z",
     "shell.execute_reply": "2021-12-09T16:43:51.411667Z",
     "shell.execute_reply.started": "2021-12-09T16:07:50.401670Z"
    },
    "papermill": {
     "duration": 0.044401,
     "end_time": "2021-12-09T16:43:51.411783",
     "exception": false,
     "start_time": "2021-12-09T16:43:51.367382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg', 'pos'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_classes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6c719007",
   "metadata": {
    "papermill": {
     "duration": 0.037314,
     "end_time": "2021-12-09T16:43:51.486944",
     "exception": false,
     "start_time": "2021-12-09T16:43:51.449630",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "处理文本的思路：\n",
    "   1. 分词\n",
    "   2. 生成词表   one--30， two--31, fuck --100\n",
    "   3. 词嵌入     30--》（0.2， 0.4， 0.2， 0.9， 2.1）  独热编码  tf-idf  hash\n",
    "                 embeddingbad 一次性实现 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deca8d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:43:51.567572Z",
     "iopub.status.busy": "2021-12-09T16:43:51.566031Z",
     "iopub.status.idle": "2021-12-09T16:43:51.568217Z",
     "shell.execute_reply": "2021-12-09T16:43:51.568636Z",
     "shell.execute_reply.started": "2021-12-09T16:07:50.410656Z"
    },
    "papermill": {
     "duration": 0.044087,
     "end_time": "2021-12-09T16:43:51.568753",
     "exception": false,
     "start_time": "2021-12-09T16:43:51.524666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer            # 分词工具\n",
    "from torchtext.vocab import build_vocab_from_iterator     # 创建词表工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5e28d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:43:51.649243Z",
     "iopub.status.busy": "2021-12-09T16:43:51.648696Z",
     "iopub.status.idle": "2021-12-09T16:43:51.652071Z",
     "shell.execute_reply": "2021-12-09T16:43:51.651651Z",
     "shell.execute_reply.started": "2021-12-09T16:07:50.419138Z"
    },
    "papermill": {
     "duration": 0.04423,
     "end_time": "2021-12-09T16:43:51.652199",
     "exception": false,
     "start_time": "2021-12-09T16:43:51.607969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')      # 分词工具做初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9323f9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:43:51.743905Z",
     "iopub.status.busy": "2021-12-09T16:43:51.734768Z",
     "iopub.status.idle": "2021-12-09T16:43:57.007004Z",
     "shell.execute_reply": "2021-12-09T16:43:57.006146Z",
     "shell.execute_reply.started": "2021-12-09T16:07:50.427283Z"
    },
    "papermill": {
     "duration": 5.316973,
     "end_time": "2021-12-09T16:43:57.007191",
     "exception": false,
     "start_time": "2021-12-09T16:43:51.690218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def yield_tokens(data):\n",
    "    for _, text in data:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_data), specials=[\"<pad>\", \"<unk>\"], min_freq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003c064a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:43:57.141528Z",
     "iopub.status.busy": "2021-12-09T16:43:57.140825Z",
     "iopub.status.idle": "2021-12-09T16:43:57.143596Z",
     "shell.execute_reply": "2021-12-09T16:43:57.144016Z",
     "shell.execute_reply.started": "2021-12-09T16:07:55.334009Z"
    },
    "papermill": {
     "duration": 0.096419,
     "end_time": "2021-12-09T16:43:57.144171",
     "exception": false,
     "start_time": "2021-12-09T16:43:57.047752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[\"<pad>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce70984d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:43:57.230474Z",
     "iopub.status.busy": "2021-12-09T16:43:57.229646Z",
     "iopub.status.idle": "2021-12-09T16:43:57.233302Z",
     "shell.execute_reply": "2021-12-09T16:43:57.232682Z",
     "shell.execute_reply.started": "2021-12-09T16:07:55.342361Z"
    },
    "papermill": {
     "duration": 0.0487,
     "end_time": "2021-12-09T16:43:57.233415",
     "exception": false,
     "start_time": "2021-12-09T16:43:57.184715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[\"<unk>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76576720",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:43:57.318205Z",
     "iopub.status.busy": "2021-12-09T16:43:57.317389Z",
     "iopub.status.idle": "2021-12-09T16:43:57.319310Z",
     "shell.execute_reply": "2021-12-09T16:43:57.319723Z",
     "shell.execute_reply.started": "2021-12-09T16:07:55.350528Z"
    },
    "papermill": {
     "duration": 0.046528,
     "end_time": "2021-12-09T16:43:57.319841",
     "exception": false,
     "start_time": "2021-12-09T16:43:57.273313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d310cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:43:57.403274Z",
     "iopub.status.busy": "2021-12-09T16:43:57.402635Z",
     "iopub.status.idle": "2021-12-09T16:43:57.405245Z",
     "shell.execute_reply": "2021-12-09T16:43:57.405672Z",
     "shell.execute_reply.started": "2021-12-09T16:07:55.358322Z"
    },
    "papermill": {
     "duration": 0.046154,
     "end_time": "2021-12-09T16:43:57.405805",
     "exception": false,
     "start_time": "2021-12-09T16:43:57.359651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'will', 'try', 'my', 'best', 'to', 'make', 'all', 'people', 'i', 'like', 'better', '.']\n"
     ]
    }
   ],
   "source": [
    "token = tokenizer('I will try my best to make all people i like better.')\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec365548",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:43:57.488523Z",
     "iopub.status.busy": "2021-12-09T16:43:57.486908Z",
     "iopub.status.idle": "2021-12-09T16:43:57.491671Z",
     "shell.execute_reply": "2021-12-09T16:43:57.491145Z",
     "shell.execute_reply.started": "2021-12-09T16:07:55.367046Z"
    },
    "papermill": {
     "duration": 0.047319,
     "end_time": "2021-12-09T16:43:57.491770",
     "exception": false,
     "start_time": "2021-12-09T16:43:57.444451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13, 86, 353, 64, 124, 8, 105, 37, 85, 13, 45, 133, 3]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144cd493",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:43:57.575687Z",
     "iopub.status.busy": "2021-12-09T16:43:57.574891Z",
     "iopub.status.idle": "2021-12-09T16:43:57.576927Z",
     "shell.execute_reply": "2021-12-09T16:43:57.577457Z",
     "shell.execute_reply.started": "2021-12-09T16:07:55.376626Z"
    },
    "papermill": {
     "duration": 0.046468,
     "end_time": "2021-12-09T16:43:57.577590",
     "exception": false,
     "start_time": "2021-12-09T16:43:57.531122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: int(x == 'pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12fa05e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:43:57.660345Z",
     "iopub.status.busy": "2021-12-09T16:43:57.659573Z",
     "iopub.status.idle": "2021-12-09T16:43:57.662931Z",
     "shell.execute_reply": "2021-12-09T16:43:57.662532Z",
     "shell.execute_reply.started": "2021-12-09T16:07:55.383668Z"
    },
    "papermill": {
     "duration": 0.046226,
     "end_time": "2021-12-09T16:43:57.663031",
     "exception": false,
     "start_time": "2021-12-09T16:43:57.616805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13, 86, 353, 64, 124, 8, 105, 37, 85, 13, 45, 133, 3]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipeline('I will try my best to make all people i like better.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbd2304",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:43:57.749298Z",
     "iopub.status.busy": "2021-12-09T16:43:57.748557Z",
     "iopub.status.idle": "2021-12-09T16:43:57.751234Z",
     "shell.execute_reply": "2021-12-09T16:43:57.751683Z",
     "shell.execute_reply.started": "2021-12-09T16:07:55.393544Z"
    },
    "papermill": {
     "duration": 0.048231,
     "end_time": "2021-12-09T16:43:57.751800",
     "exception": false,
     "start_time": "2021-12-09T16:43:57.703569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_pipeline('pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5e37bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([   1, 1228,    4,    1,    4,    1]), tensor([   1,   44, 6575,    3])]\n",
      "tensor([   1, 1228,    4,    1,    4,    1,    1,   44, 6575,    3])\n",
      "tensor([[   1,    1],\n",
      "        [1228,   44],\n",
      "        [   4, 6575],\n",
      "        [   1,    3],\n",
      "        [   4,    0],\n",
      "        [   1,    0]])\n"
     ]
    }
   ],
   "source": [
    "text_list_o = []\n",
    "text_list_o.append(torch.tensor(text_pipeline('fuck u,LYB,NMSL'),dtype=torch.int64))\n",
    "text_list_o.append(torch.tensor(text_pipeline('cubit so dump.'),dtype=torch.int64))\n",
    "\n",
    "text_list_1 = torch.cat(text_list_o)\n",
    "text_list_2 = torch.nn.utils.rnn.pad_sequence(text_list_o)\n",
    "# 注意是按列看的\n",
    "print(text_list_o)\n",
    "\n",
    "print(text_list_1)\n",
    "print(text_list_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ae0333",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:43:57.883221Z",
     "iopub.status.busy": "2021-12-09T16:43:57.882334Z",
     "iopub.status.idle": "2021-12-09T16:43:57.884837Z",
     "shell.execute_reply": "2021-12-09T16:43:57.884184Z",
     "shell.execute_reply.started": "2021-12-09T16:07:55.405271Z"
    },
    "papermill": {
     "duration": 0.092461,
     "end_time": "2021-12-09T16:43:57.884952",
     "exception": false,
     "start_time": "2021-12-09T16:43:57.792491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b665a62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:43:57.972725Z",
     "iopub.status.busy": "2021-12-09T16:43:57.969958Z",
     "iopub.status.idle": "2021-12-09T16:43:57.975218Z",
     "shell.execute_reply": "2021-12-09T16:43:57.974649Z",
     "shell.execute_reply.started": "2021-12-09T16:07:55.466132Z"
    },
    "papermill": {
     "duration": 0.049653,
     "end_time": "2021-12-09T16:43:57.975336",
     "exception": false,
     "start_time": "2021-12-09T16:43:57.925683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# embeddingbag 层输入 拼接好的batch句子 和 offset（每个句子起始的位置）但是RNN不需要offset\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list = [], []\n",
    "    for (_label, _text) in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        precess_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        text_list.append(precess_text)\n",
    "    label_list = torch.tensor(label_list)\n",
    "    # 此时，text_list的长度不同 通过torch.nn.utils.rnn.pad_sequence 按照序列中最长的序列进行填充\n",
    "    text_list = torch.nn.utils.rnn.pad_sequence(text_list)\n",
    "    return label_list.to(device), text_list.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769a4fc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:43:58.062112Z",
     "iopub.status.busy": "2021-12-09T16:43:58.061417Z",
     "iopub.status.idle": "2021-12-09T16:43:58.063952Z",
     "shell.execute_reply": "2021-12-09T16:43:58.063543Z",
     "shell.execute_reply.started": "2021-12-09T16:10:01.979776Z"
    },
    "papermill": {
     "duration": 0.047182,
     "end_time": "2021-12-09T16:43:58.064056",
     "exception": false,
     "start_time": "2021-12-09T16:43:58.016874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=16, shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_data, batch_size=16, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6a9121",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:43:58.147873Z",
     "iopub.status.busy": "2021-12-09T16:43:58.146990Z",
     "iopub.status.idle": "2021-12-09T16:44:01.541806Z",
     "shell.execute_reply": "2021-12-09T16:44:01.540994Z",
     "shell.execute_reply.started": "2021-12-09T16:10:02.602820Z"
    },
    "papermill": {
     "duration": 3.437238,
     "end_time": "2021-12-09T16:44:01.541936",
     "exception": false,
     "start_time": "2021-12-09T16:43:58.104698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16]) torch.Size([535, 16])\n",
      "torch.Size([16]) torch.Size([763, 16])\n",
      "torch.Size([16]) torch.Size([535, 16])\n",
      "torch.Size([16]) torch.Size([339, 16])\n",
      "torch.Size([16]) torch.Size([1127, 16])\n",
      "torch.Size([16]) torch.Size([372, 16])\n",
      "torch.Size([16]) torch.Size([1169, 16])\n",
      "torch.Size([16]) torch.Size([598, 16])\n",
      "torch.Size([16]) torch.Size([727, 16])\n",
      "torch.Size([16]) torch.Size([1049, 16])\n",
      "torch.Size([16]) torch.Size([862, 16])\n"
     ]
    }
   ],
   "source": [
    "for i, (l, b) in enumerate(train_dataloader):\n",
    "    print(l.size(), b.size())\n",
    "    if i>9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3fb69e",
   "metadata": {
    "papermill": {
     "duration": 0.040091,
     "end_time": "2021-12-09T16:44:01.623808",
     "exception": false,
     "start_time": "2021-12-09T16:44:01.583717",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e172050",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:44:01.708576Z",
     "iopub.status.busy": "2021-12-09T16:44:01.707796Z",
     "iopub.status.idle": "2021-12-09T16:44:01.710632Z",
     "shell.execute_reply": "2021-12-09T16:44:01.710193Z",
     "shell.execute_reply.started": "2021-12-09T16:10:03.196571Z"
    },
    "papermill": {
     "duration": 0.0465,
     "end_time": "2021-12-09T16:44:01.710734",
     "exception": false,
     "start_time": "2021-12-09T16:44:01.664234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a67ce13",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1,c1 = nn.LSTM(input,(h0,c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e94cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_net():\n",
    "    def __init__(self, input_seq_len, hidden):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.LSTMCell(input_seq_len,hidden)\n",
    "    def forward(self, inputs):\n",
    "        bz = inputs.shape[1]\n",
    "        ht = torch.zeros(bz, hidden).to(device)\n",
    "        ct = torch.zeros(bz, hidden).to(device)\n",
    "        for word in inputs:\n",
    "            ht,ct = self.rnn(word,(ht,ct))\n",
    "        return ht, ct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b506c016",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:44:01.976753Z",
     "iopub.status.busy": "2021-12-09T16:44:01.975985Z",
     "iopub.status.idle": "2021-12-09T16:44:01.978322Z",
     "shell.execute_reply": "2021-12-09T16:44:01.977780Z",
     "shell.execute_reply.started": "2021-12-09T16:10:03.566000Z"
    },
    "papermill": {
     "duration": 0.048942,
     "end_time": "2021-12-09T16:44:01.978428",
     "exception": false,
     "start_time": "2021-12-09T16:44:01.929486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RNN_Net(nn.Module):\n",
    "    def __init__(self, vocab_size, embeding_dim, hidden_size):\n",
    "        super(RNN_Net, self).__init__()\n",
    "        self.em = nn.Embedding(vocab_size, embeding_dim)   \n",
    "        # embedding 会依照vocab的大小对输入的单词进行编码，到embeding_dim这样的大小\n",
    "        self.rnn = nn.LSTM(embeding_dim, hidden_size)\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.em(inputs)\n",
    "        x, _ = self.rnn(x)\n",
    "#        print(x.size(), o.size())\n",
    "        x = F.relu(self.fc1(x[-1]))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dece85a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:44:02.065944Z",
     "iopub.status.busy": "2021-12-09T16:44:02.065395Z",
     "iopub.status.idle": "2021-12-09T16:44:02.826550Z",
     "shell.execute_reply": "2021-12-09T16:44:02.827090Z",
     "shell.execute_reply.started": "2021-12-09T16:10:03.741603Z"
    },
    "papermill": {
     "duration": 0.808191,
     "end_time": "2021-12-09T16:44:02.827297",
     "exception": false,
     "start_time": "2021-12-09T16:44:02.019106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeding_dim = 256\n",
    "hidden_size = 128\n",
    "model = RNN_Net(vocab_size, embeding_dim, hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a117ccc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:44:02.912400Z",
     "iopub.status.busy": "2021-12-09T16:44:02.911594Z",
     "iopub.status.idle": "2021-12-09T16:44:02.917016Z",
     "shell.execute_reply": "2021-12-09T16:44:02.916615Z",
     "shell.execute_reply.started": "2021-12-09T16:10:03.932097Z"
    },
    "papermill": {
     "duration": 0.048627,
     "end_time": "2021-12-09T16:44:02.917141",
     "exception": false,
     "start_time": "2021-12-09T16:44:02.868514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "from torch.optim import lr_scheduler\n",
    "optimizer = torch.optim.Adam(model.parameters(), betas=(0.5, 0.5), lr=0.01)\n",
    "# betas=(0.5, 0.5) 一阶矩估计和二阶矩估计均为0.5\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eeb839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([[  13,  295,   99,  ...,   13,    6,  157],\n",
      "        [ 125,    2,    6,  ...,  220,  589,    4],\n",
      "        [1051,  706,  483,  ...,    2,    7,   13],\n",
      "        ...,\n",
      "        [   0,    0,    0,  ...,   19,    0,    0],\n",
      "        [   0,    0,    0,  ...,   15,    0,    0],\n",
      "        [   0,    0,    0,  ...,    3,    0,    0]])\n"
     ]
    }
   ],
   "source": [
    "for label, text in test_dataloader:\n",
    "    print(label,text)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1549de3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:44:03.005270Z",
     "iopub.status.busy": "2021-12-09T16:44:03.002008Z",
     "iopub.status.idle": "2021-12-09T16:44:03.007958Z",
     "shell.execute_reply": "2021-12-09T16:44:03.007408Z",
     "shell.execute_reply.started": "2021-12-09T16:10:04.112375Z"
    },
    "papermill": {
     "duration": 0.050105,
     "end_time": "2021-12-09T16:44:03.008084",
     "exception": false,
     "start_time": "2021-12-09T16:44:02.957979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(dataloader):\n",
    "    total_acc, total_count, total_loss, = 0, 0, 0\n",
    "    model.train()\n",
    "    for label, text in dataloader:\n",
    "        predicted_label = model(text)\n",
    "        loss = loss_fn(predicted_label, label)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "            total_loss += loss.item()*label.size(0)\n",
    "    return total_loss/total_count, total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97802301",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:44:03.097194Z",
     "iopub.status.busy": "2021-12-09T16:44:03.096353Z",
     "iopub.status.idle": "2021-12-09T16:44:03.098849Z",
     "shell.execute_reply": "2021-12-09T16:44:03.098408Z",
     "shell.execute_reply.started": "2021-12-09T16:10:04.296062Z"
    },
    "papermill": {
     "duration": 0.049449,
     "end_time": "2021-12-09T16:44:03.098954",
     "exception": false,
     "start_time": "2021-12-09T16:44:03.049505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count, total_loss, = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for label, text in dataloader:\n",
    "            predicted_label = model(text)\n",
    "            loss = loss_fn(predicted_label, label)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "            total_loss += loss.item()*label.size(0)\n",
    "    return total_loss/total_count, total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705583c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:44:03.189493Z",
     "iopub.status.busy": "2021-12-09T16:44:03.188737Z",
     "iopub.status.idle": "2021-12-09T16:44:03.191154Z",
     "shell.execute_reply": "2021-12-09T16:44:03.190706Z",
     "shell.execute_reply.started": "2021-12-09T16:10:04.479118Z"
    },
    "papermill": {
     "duration": 0.050589,
     "end_time": "2021-12-09T16:44:03.191268",
     "exception": false,
     "start_time": "2021-12-09T16:44:03.140679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit(epochs, train_dl, test_dl):\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    test_loss = []\n",
    "    test_acc = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss, epoch_acc = train(train_dl)\n",
    "        epoch_test_loss, epoch_test_acc = test(test_dl)\n",
    "        train_loss.append(epoch_loss)\n",
    "        train_acc.append(epoch_acc)\n",
    "        test_loss.append(epoch_test_loss)\n",
    "        test_acc.append(epoch_test_acc)\n",
    "        exp_lr_scheduler.step()\n",
    "        template = (\"epoch:{:2d}, train_loss: {:.5f}, train_acc: {:.1f}% ,\" \n",
    "                    \"test_loss: {:.5f}, test_acc: {:.1f}%\")\n",
    "        print(template.format(\n",
    "              epoch, epoch_loss, epoch_acc*100, epoch_test_loss, epoch_test_acc*100))\n",
    "    print(\"Done!\")\n",
    "    \n",
    "    return train_loss, test_loss, train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcab82a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:44:03.277246Z",
     "iopub.status.busy": "2021-12-09T16:44:03.276488Z",
     "iopub.status.idle": "2021-12-09T16:44:03.278908Z",
     "shell.execute_reply": "2021-12-09T16:44:03.278463Z",
     "shell.execute_reply.started": "2021-12-09T16:10:04.667876Z"
    },
    "papermill": {
     "duration": 0.047026,
     "end_time": "2021-12-09T16:44:03.279008",
     "exception": false,
     "start_time": "2021-12-09T16:44:03.231982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f22463",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T16:44:03.366268Z",
     "iopub.status.busy": "2021-12-09T16:44:03.365540Z",
     "iopub.status.idle": "2021-12-09T17:30:09.612518Z",
     "shell.execute_reply": "2021-12-09T17:30:09.613003Z"
    },
    "papermill": {
     "duration": 2766.291985,
     "end_time": "2021-12-09T17:30:09.613190",
     "exception": false,
     "start_time": "2021-12-09T16:44:03.321205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\cherium\\Desktop\\Python\\ML\\DL\\9 RNN\\02 RNN LSTM GRU 表示\\basic-lstm classification.ipynb 单元格 39\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/cherium/Desktop/Python/ML/DL/9%20RNN/02%20RNN%20LSTM%20GRU%20%E8%A1%A8%E7%A4%BA/basic-lstm%20classification.ipynb#X55sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_loss, test_loss, train_acc, test_acc \u001b[39m=\u001b[39m fit(EPOCHS, train_dataloader, test_dataloader)\n",
      "\u001b[1;32md:\\cherium\\Desktop\\Python\\ML\\DL\\9 RNN\\02 RNN LSTM GRU 表示\\basic-lstm classification.ipynb 单元格 39\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/cherium/Desktop/Python/ML/DL/9%20RNN/02%20RNN%20LSTM%20GRU%20%E8%A1%A8%E7%A4%BA/basic-lstm%20classification.ipynb#X55sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m test_acc \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/cherium/Desktop/Python/ML/DL/9%20RNN/02%20RNN%20LSTM%20GRU%20%E8%A1%A8%E7%A4%BA/basic-lstm%20classification.ipynb#X55sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/cherium/Desktop/Python/ML/DL/9%20RNN/02%20RNN%20LSTM%20GRU%20%E8%A1%A8%E7%A4%BA/basic-lstm%20classification.ipynb#X55sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     epoch_loss, epoch_acc \u001b[39m=\u001b[39m train(train_dl)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/cherium/Desktop/Python/ML/DL/9%20RNN/02%20RNN%20LSTM%20GRU%20%E8%A1%A8%E7%A4%BA/basic-lstm%20classification.ipynb#X55sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     epoch_test_loss, epoch_test_acc \u001b[39m=\u001b[39m test(test_dl)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/cherium/Desktop/Python/ML/DL/9%20RNN/02%20RNN%20LSTM%20GRU%20%E8%A1%A8%E7%A4%BA/basic-lstm%20classification.ipynb#X55sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     train_loss\u001b[39m.\u001b[39mappend(epoch_loss)\n",
      "\u001b[1;32md:\\cherium\\Desktop\\Python\\ML\\DL\\9 RNN\\02 RNN LSTM GRU 表示\\basic-lstm classification.ipynb 单元格 39\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/cherium/Desktop/Python/ML/DL/9%20RNN/02%20RNN%20LSTM%20GRU%20%E8%A1%A8%E7%A4%BA/basic-lstm%20classification.ipynb#X55sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/cherium/Desktop/Python/ML/DL/9%20RNN/02%20RNN%20LSTM%20GRU%20%E8%A1%A8%E7%A4%BA/basic-lstm%20classification.ipynb#X55sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m label, text \u001b[39min\u001b[39;00m dataloader:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/cherium/Desktop/Python/ML/DL/9%20RNN/02%20RNN%20LSTM%20GRU%20%E8%A1%A8%E7%A4%BA/basic-lstm%20classification.ipynb#X55sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     predicted_label \u001b[39m=\u001b[39m model(text)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/cherium/Desktop/Python/ML/DL/9%20RNN/02%20RNN%20LSTM%20GRU%20%E8%A1%A8%E7%A4%BA/basic-lstm%20classification.ipynb#X55sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     loss \u001b[39m=\u001b[39m loss_fn(predicted_label, label)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/cherium/Desktop/Python/ML/DL/9%20RNN/02%20RNN%20LSTM%20GRU%20%E8%A1%A8%E7%A4%BA/basic-lstm%20classification.ipynb#X55sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m# Backpropagation\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cherium\\scoop\\apps\\miniconda3\\current\\envs\\torch19\\lib\\site-packages\\torch\\nn\\modules\\module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1047\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1048\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1052\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32md:\\cherium\\Desktop\\Python\\ML\\DL\\9 RNN\\02 RNN LSTM GRU 表示\\basic-lstm classification.ipynb 单元格 39\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/cherium/Desktop/Python/ML/DL/9%20RNN/02%20RNN%20LSTM%20GRU%20%E8%A1%A8%E7%A4%BA/basic-lstm%20classification.ipynb#X55sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, inputs):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/cherium/Desktop/Python/ML/DL/9%20RNN/02%20RNN%20LSTM%20GRU%20%E8%A1%A8%E7%A4%BA/basic-lstm%20classification.ipynb#X55sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mem(inputs)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/cherium/Desktop/Python/ML/DL/9%20RNN/02%20RNN%20LSTM%20GRU%20%E8%A1%A8%E7%A4%BA/basic-lstm%20classification.ipynb#X55sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         x, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrnn(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/cherium/Desktop/Python/ML/DL/9%20RNN/02%20RNN%20LSTM%20GRU%20%E8%A1%A8%E7%A4%BA/basic-lstm%20classification.ipynb#X55sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m#        print(x.size(), o.size())\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/cherium/Desktop/Python/ML/DL/9%20RNN/02%20RNN%20LSTM%20GRU%20%E8%A1%A8%E7%A4%BA/basic-lstm%20classification.ipynb#X55sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1(x[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]))\n",
      "File \u001b[1;32mc:\\Users\\cherium\\scoop\\apps\\miniconda3\\current\\envs\\torch19\\lib\\site-packages\\torch\\nn\\modules\\module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1047\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1048\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1052\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\cherium\\scoop\\apps\\miniconda3\\current\\envs\\torch19\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:679\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m    678\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 679\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[0;32m    680\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[0;32m    681\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    682\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[0;32m    683\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss, test_loss, train_acc, test_acc = fit(EPOCHS, train_dataloader, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11728c92",
   "metadata": {
    "papermill": {
     "duration": 0.067801,
     "end_time": "2021-12-09T17:30:09.880639",
     "exception": false,
     "start_time": "2021-12-09T17:30:09.812838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be0ac11",
   "metadata": {
    "papermill": {
     "duration": 0.066,
     "end_time": "2021-12-09T17:30:10.013678",
     "exception": false,
     "start_time": "2021-12-09T17:30:09.947678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4074680",
   "metadata": {
    "papermill": {
     "duration": 0.067024,
     "end_time": "2021-12-09T17:30:10.147975",
     "exception": false,
     "start_time": "2021-12-09T17:30:10.080951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2863.29538,
   "end_time": "2021-12-09T17:30:11.434354",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-12-09T16:42:28.138974",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
